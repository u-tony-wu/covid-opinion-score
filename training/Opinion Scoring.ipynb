{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers as trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DistilBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = trf.DistilBertModel\n",
    "tokenizer_class = trf.DistilBertTokenizer\n",
    "pretrained_weights = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2651, 2003, 1037, 2204, 2154, 102]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('today is a good day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distilBERT model\n",
    "#model = model_class.from_pretrained(pretrained_weights)\n",
    "dBERT_model = torch.load('distill_bert0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dBERT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'distill_bert0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 2651, 2003, 1037, 2204, 2154,  102])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_x = torch.tensor(tokenizer.encode('today is a good day'))\n",
    "try_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_x = try_x.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2651, 2003, 1037, 2204, 2154,  102]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.0024, -0.1809,  0.1915,  ..., -0.0416,  0.4621,  0.0992],\n",
       "         [-0.2186,  0.0181, -0.1486,  ..., -0.4835,  0.5390, -0.5484],\n",
       "         [-0.4523, -0.1693,  0.4058,  ..., -0.5069,  0.2973,  0.3459],\n",
       "         ...,\n",
       "         [ 0.0654,  0.1925,  0.5155,  ..., -0.2969,  0.2309, -0.7778],\n",
       "         [-0.1178, -0.1854,  0.1412,  ...,  0.0207,  0.1747, -0.9925],\n",
       "         [ 0.8455,  0.1028, -0.3025,  ...,  0.0966, -0.4139, -0.3374]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dBERT_model(try_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data + Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "with open('train_test_data_v2/pos_tweets.pkl', 'rb') as f:\n",
    "    pos_data = pickle.load(f)\n",
    "\n",
    "with open('train_test_data_v2/semi_pos_tweets.pkl', 'rb') as f:\n",
    "    semi_pos_data = pickle.load(f)\n",
    "\n",
    "with open('train_test_data_v2/neutral_augmented.pkl', 'rb') as f:\n",
    "    neu_data = pickle.load(f)\n",
    "\n",
    "with open('train_test_data_v2/semi_neg_tweets.pkl', 'rb') as f:\n",
    "    semi_neg_data = pickle.load(f)\n",
    "    \n",
    "with open('train_test_data_v2/neg_tweets.pkl', 'rb') as f:\n",
    "    neg_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13410"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13410\n",
      "6700\n"
     ]
    }
   ],
   "source": [
    "def random_select(tweets, filter_ratio=1):\n",
    "    print(len(tweets))\n",
    "    ret = []\n",
    "    for tweet in tweets:\n",
    "        if np.random.randint(filter_ratio) == 0:\n",
    "            ret.append(tweet)\n",
    "    print(len(ret))\n",
    "    return ret\n",
    "\n",
    "pos_data = random_select(pos_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5451\n",
      "6849\n",
      "4597\n",
      "5542\n"
     ]
    }
   ],
   "source": [
    "print(len(semi_pos_data))\n",
    "print(len(neu_data))\n",
    "print(len(semi_neg_data))\n",
    "print(len(neg_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, sentence_list):\n",
    "    ret = []\n",
    "    for i in range(len(sentence_list)):\n",
    "        if i%500 == 0:\n",
    "            print('On row %d'%i)\n",
    "        new_input = torch.tensor(tokenizer.encode(sentence_list[i])).reshape(1,-1)\n",
    "        with torch.no_grad():\n",
    "            new_output = model(new_input).last_hidden_state[0][0]\n",
    "        ret.append(np.array(new_output).reshape(1,-1))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29139\n"
     ]
    }
   ],
   "source": [
    "tweets_data = pos_data + semi_pos_data + neu_data + semi_neg_data + neg_data\n",
    "tweets_data = [remove_url(tweet) for tweet in tweets_data]\n",
    "print(len(tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please wear a mask! Not because you are sick, but also protect yourself and others! #wearamask #COVID19  '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On row 0\n",
      "On row 500\n",
      "On row 1000\n",
      "On row 1500\n",
      "On row 2000\n",
      "On row 2500\n",
      "On row 3000\n",
      "On row 3500\n",
      "On row 4000\n",
      "On row 4500\n",
      "On row 5000\n",
      "On row 5500\n",
      "On row 6000\n",
      "On row 6500\n",
      "On row 7000\n",
      "On row 7500\n",
      "On row 8000\n",
      "On row 8500\n",
      "On row 9000\n",
      "On row 9500\n",
      "On row 10000\n",
      "On row 10500\n",
      "On row 11000\n",
      "On row 11500\n",
      "On row 12000\n",
      "On row 12500\n",
      "On row 13000\n",
      "On row 13500\n",
      "On row 14000\n",
      "On row 14500\n",
      "On row 15000\n",
      "On row 15500\n",
      "On row 16000\n",
      "On row 16500\n",
      "On row 17000\n",
      "On row 17500\n",
      "On row 18000\n",
      "On row 18500\n",
      "On row 19000\n",
      "On row 19500\n",
      "On row 20000\n",
      "On row 20500\n",
      "On row 21000\n",
      "On row 21500\n",
      "On row 22000\n",
      "On row 22500\n",
      "On row 23000\n",
      "On row 23500\n",
      "On row 24000\n",
      "On row 24500\n",
      "On row 25000\n",
      "On row 25500\n",
      "On row 26000\n",
      "On row 26500\n",
      "On row 27000\n",
      "On row 27500\n",
      "On row 28000\n",
      "On row 28500\n",
      "On row 29000\n"
     ]
    }
   ],
   "source": [
    "# Get sentence embeddings\n",
    "emb_list = get_embeddings(dBERT_model, tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29139, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.concatenate((emb_list),axis=0)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('emb.npy','wb') as f:\n",
    "#    np.save(f, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('tweet_emb.npy','rb') as f:\n",
    "#    embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding-to-score PyTorch model\n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(768,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.tanh(self.linear(x))\n",
    "\n",
    "\n",
    "class TwoLayerScoreNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(768,128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ret = self.relu(self.linear1(x))\n",
    "        ret = self.linear2(ret)\n",
    "        return torch.tanh(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27528 28383 13349  8833 15029 10871 28427 17342 28805  2576]\n"
     ]
    }
   ],
   "source": [
    "shuffled_index = np.arange(len(embeddings))\n",
    "np.random.shuffle(shuffled_index)\n",
    "print(shuffled_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23311,)\n",
      "(5828,)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.8*len(embeddings))\n",
    "train_index = shuffled_index[:split]\n",
    "test_index = shuffled_index[split:]\n",
    "\n",
    "print(train_index.shape)\n",
    "print(test_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = np.array(([1]*len(pos_data) + [0.5]*len(semi_pos_data) + [0]*len(neu_data) \n",
    "              + [-0.5]*len(semi_neg_data) + [-1]*len(neg_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29139, 768)\n",
      "(29139,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = X[train_index], y[train_index], X[test_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train).reshape(-1,1)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23311, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5000, lr=1e-3):\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        y_out = model(X_train)\n",
    "        loss = (y_out-y_train).pow(2).sum()\n",
    "\n",
    "        if iteration%(int(epochs/10)) == 0:\n",
    "            print('On epoch %d: '%iteration, 'Loss: %d'%loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch 0:  Loss: 12534\n",
      "On epoch 500:  Loss: 2903\n",
      "On epoch 1000:  Loss: 2617\n",
      "On epoch 1500:  Loss: 2488\n",
      "On epoch 2000:  Loss: 2412\n",
      "On epoch 2500:  Loss: 2363\n",
      "On epoch 3000:  Loss: 2331\n",
      "On epoch 3500:  Loss: 2310\n",
      "On epoch 4000:  Loss: 2296\n",
      "On epoch 4500:  Loss: 2287\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "snet = ScoreNet()\n",
    "train(snet, 5000, 2*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch 0:  Loss: 2290\n",
      "On epoch 500:  Loss: 2279\n",
      "On epoch 1000:  Loss: 2277\n",
      "On epoch 1500:  Loss: 2274\n",
      "On epoch 2000:  Loss: 2271\n",
      "On epoch 2500:  Loss: 2268\n",
      "On epoch 3000:  Loss: 2267\n",
      "On epoch 3500:  Loss: 2265\n",
      "On epoch 4000:  Loss: 2263\n",
      "On epoch 4500:  Loss: 2262\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "train(snet, 5000, 2*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch 0:  Loss: 11710\n",
      "On epoch 100:  Loss: 2993\n",
      "On epoch 200:  Loss: 2245\n",
      "On epoch 300:  Loss: 1968\n",
      "On epoch 400:  Loss: 1803\n",
      "On epoch 500:  Loss: 1701\n",
      "On epoch 600:  Loss: 1591\n",
      "On epoch 700:  Loss: 1504\n",
      "On epoch 800:  Loss: 1432\n",
      "On epoch 900:  Loss: 1391\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "snet_v2 = TwoLayerScoreNet()\n",
    "train(snet_v2, 1000, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch 0:  Loss: 1330\n",
      "On epoch 100:  Loss: 1291\n",
      "On epoch 200:  Loss: 1272\n",
      "On epoch 300:  Loss: 1248\n",
      "On epoch 400:  Loss: 1222\n",
      "On epoch 500:  Loss: 1193\n",
      "On epoch 600:  Loss: 1163\n",
      "On epoch 700:  Loss: 1132\n",
      "On epoch 800:  Loss: 1100\n",
      "On epoch 900:  Loss: 1070\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "train(snet_v2, 1000, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternatively, use sklearn linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge # linear classifier with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRclassifier = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907537159600979"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRclassifier.score(X_train, y_train) # R^2 score of predicted and actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777609448987791"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRclassifier.score(X_test, y_test) # R^2 score of predicted and actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_classifier = Ridge(alpha=1) # alpha=1 gives the best result, compared to alpha=0.1 or 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903840948098128"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7786628584490942"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on training data:  0.8070095105173132\n",
      "performance on test data:  0.795529087896512\n"
     ]
    }
   ],
   "source": [
    "# best\n",
    "print('performance on training data: ', r2_score(y_train, snet(X_train).detach()))\n",
    "print('performance on test data: ', r2_score(y_test, snet(X_test).detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on training data:  0.9111099758831454\n",
      "performance on test data:  0.8503452651247398\n"
     ]
    }
   ],
   "source": [
    "print('performance on training data: ', r2_score(y_train, snet_v2(X_train).detach()))\n",
    "print('performance on test data: ', r2_score(y_test, snet_v2(X_test).detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on training data:  0.7903840948098129\n",
      "performance on test data:  0.7786628584490942\n"
     ]
    }
   ],
   "source": [
    "print('performance on training data: ', r2_score(y_train, Ridge_classifier.predict(X_train)))\n",
    "print('performance on test data: ', r2_score(y_test, Ridge_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on training data:  0.7907537159600979\n",
      "performance on test data:  0.7777609448987791\n"
     ]
    }
   ],
   "source": [
    "print('performance on training data: ', r2_score(y_train, LRclassifier.predict(X_train)))\n",
    "print('performance on test data: ', r2_score(y_test, LRclassifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9287555813789368, 0.4493280351161957, -0.4090578556060791, -0.8656989932060242, 0.7675151824951172, 0.2942424714565277, 0.6786667108535767, 0.9472098350524902, -0.6245620250701904, -0.7595279216766357]\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(snet_v2(X_test).detach())\n",
    "y_pred = [val.item() for val in y_pred]\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_class(scores):\n",
    "    ret = []\n",
    "    for score in scores:\n",
    "        if score > 0.6: \n",
    "            ret += [0] # positive\n",
    "        elif score >0.2:\n",
    "            ret += [1] # semi-positive\n",
    "        elif score >=-0.2:\n",
    "            ret += [2] # neutral\n",
    "        elif score >= -0.6:\n",
    "            ret += [3] # semi-negative\n",
    "        else:\n",
    "            ret += [4] #negative\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_class_rough(scores, threshold=0.25):\n",
    "    ret = []\n",
    "    for score in scores:\n",
    "        if score > threshold:\n",
    "            ret += [0] # positive or semi-positive\n",
    "        elif score >= -threshold:\n",
    "            ret += [1] # neutral\n",
    "        else:\n",
    "            ret += [2] #negative or semi-negative\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.25 # cutoff between positive and neutral (and between neutral and negative)\n",
    "\n",
    "y_pred_class = score_to_class_rough(y_pred, cutoff)\n",
    "y_test_class = score_to_class_rough([val.item() for val in list(y_test)], cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2323  155    5]\n",
      " [ 250  828  254]\n",
      " [   9  131 1873]] \n",
      "\n",
      "accuracy:  0.862\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test_class, y_pred_class)\n",
    "print(conf_mat, '\\n')\n",
    "\n",
    "correct_count = 0\n",
    "for i in range(len(conf_mat)):\n",
    "    correct_count += conf_mat[i][i]\n",
    "print('accuracy: ', round(correct_count/len(y_test_class),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[-0.0725,  0.0076,  0.0362,  ..., -0.0614, -0.1010,  0.0308],\n",
      "        [-0.1231, -0.0637, -0.0137,  ..., -0.0846,  0.0417, -0.0195],\n",
      "        [-0.0375,  0.0009,  0.0017,  ..., -0.0264, -0.0401, -0.0260],\n",
      "        ...,\n",
      "        [-0.0559, -0.0550,  0.0466,  ..., -0.0745,  0.0075,  0.0189],\n",
      "        [ 0.1420,  0.0347, -0.0662,  ..., -0.0181, -0.0549, -0.0399],\n",
      "        [ 0.0042, -0.0030, -0.0250,  ...,  0.0006,  0.0322, -0.0294]])\n",
      "linear1.bias tensor([-0.0107, -0.0102,  0.0274, -0.0259,  0.0266,  0.0050,  0.0221,  0.0081,\n",
      "        -0.0262,  0.0292,  0.0154, -0.0187, -0.0189,  0.0166, -0.0121, -0.0321,\n",
      "         0.0097,  0.0155,  0.0028, -0.0012, -0.0020,  0.0196,  0.0039,  0.0045,\n",
      "        -0.0247,  0.0020,  0.0034,  0.0026, -0.0117,  0.0240,  0.0165,  0.0202,\n",
      "        -0.0037,  0.0112,  0.0207,  0.0197,  0.0362, -0.0344,  0.0056,  0.0136,\n",
      "         0.0304, -0.0191,  0.0186,  0.0129, -0.0015, -0.0084,  0.0190,  0.0174,\n",
      "        -0.0161, -0.0137,  0.0194,  0.0312, -0.0264, -0.0177, -0.0322,  0.0254,\n",
      "        -0.0121, -0.0340,  0.0389, -0.0264,  0.0108, -0.0169, -0.0147, -0.0141,\n",
      "        -0.0016, -0.0337, -0.0220, -0.0307,  0.0154,  0.0192, -0.0002, -0.0041,\n",
      "         0.0229, -0.0340,  0.0072, -0.0142, -0.0342, -0.0138,  0.0213, -0.0292,\n",
      "         0.0252,  0.0194,  0.0157, -0.0288, -0.0156,  0.0237, -0.0214,  0.0356,\n",
      "         0.0206, -0.0048, -0.0262,  0.0278,  0.0118, -0.0354, -0.0300, -0.0064,\n",
      "        -0.0157, -0.0067,  0.0023,  0.0134, -0.0250,  0.0042, -0.0082,  0.0226,\n",
      "        -0.0400, -0.0097,  0.0003, -0.0151,  0.0211, -0.0129, -0.0204, -0.0006,\n",
      "         0.0187,  0.0147, -0.0181, -0.0354,  0.0343, -0.0060,  0.0134, -0.0074,\n",
      "        -0.0387,  0.0268,  0.0323, -0.0172, -0.0155,  0.0043,  0.0293, -0.0022])\n",
      "linear2.weight tensor([[ 0.2131, -0.3233,  0.0052, -0.0649,  0.6912,  0.0473, -0.1011,  0.2570,\n",
      "          0.3355,  0.0319, -0.0201, -0.1766, -0.3333,  0.2022, -0.3645,  0.0081,\n",
      "          0.2716,  0.1987,  0.2572, -0.2636,  0.0725,  0.2473, -0.3877, -0.1702,\n",
      "         -0.0786,  0.1277, -0.0439, -0.0730, -0.3560, -0.5649,  0.0529, -0.0154,\n",
      "          0.2739, -0.1621, -0.0535, -0.2647,  0.3478, -0.0744, -0.0181,  0.0614,\n",
      "          0.2467,  0.0571, -0.1024,  0.2216, -0.0253,  0.2022, -0.2624,  0.3512,\n",
      "         -0.0019, -0.0996, -0.0585,  0.3754,  0.2763,  0.1714, -0.0769,  0.2963,\n",
      "          0.0049, -0.2169,  0.1350,  0.2337, -0.3333,  0.0577,  0.2722, -0.1846,\n",
      "         -0.2549, -0.0494, -0.1162, -0.0370,  0.0537, -0.1048, -0.2868,  0.2645,\n",
      "         -0.3108,  0.2368,  0.0566,  0.0711,  0.2756,  0.1890,  0.1662, -0.2075,\n",
      "         -0.0815, -0.1512, -0.1114, -0.1565, -0.0417, -0.1625, -0.2377,  0.1858,\n",
      "          0.2447, -0.2921,  0.0937, -0.1857, -0.2019, -0.2135, -0.0151,  0.2538,\n",
      "         -0.0850,  0.0184,  0.1794, -0.0862, -0.2816, -0.0620,  0.2585, -0.0417,\n",
      "          0.0194, -0.2647, -0.0806, -0.0811,  0.0473, -0.1450,  0.1014, -0.0443,\n",
      "         -0.1291,  0.0413, -0.0987, -0.1753,  0.2043, -0.2292,  0.0394,  0.2073,\n",
      "          0.0504,  0.0591,  0.0958, -0.0692, -0.0801, -0.2926,  0.4082, -0.0439]])\n",
      "linear2.bias tensor([0.0200])\n"
     ]
    }
   ],
   "source": [
    "for name, param in snet_v2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(snet.state_dict(), 'OneLayerScoreModel.pth')\n",
    "# torch.save(snet_v2.state_dict(), 'TwoLayerScoreModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7261]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loading model\n",
    "# test_model = ScoreNet()\n",
    "# test_model.load_state_dict(torch.load('OneLayerScoreModel.pth'))\n",
    "# test_model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on real, unseen tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(sentence, score_model):\n",
    "    sentence = remove_url(sentence.lower())\n",
    "    x = torch.tensor(tokenizer.encode(sentence)).reshape(1,-1)\n",
    "    with torch.no_grad():\n",
    "        cls = dBERT_model(x).last_hidden_state[0][0].reshape(1,768)\n",
    "    pred = score_model(cls)\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tweet_and_pred(df, classifier_model, num_tweets=10, show_index=False, show_label=False):\n",
    "    for i in range(num_tweets):\n",
    "        rand_id = np.random.randint(len(df))\n",
    "        tweet = df['tweet'][rand_id]\n",
    "        \n",
    "        if show_index:\n",
    "            print(df['index'][rand_id])\n",
    "        \n",
    "        print(tweet)\n",
    "        score = make_prediction(tweet, classifier_model)\n",
    "        if show_label:\n",
    "            category = ''\n",
    "            if score > 0.3:\n",
    "                category = 'positive'\n",
    "            elif score < -0.3:\n",
    "                category = 'negative'\n",
    "            else:\n",
    "                category = 'neutral/irrelevant'\n",
    "            print('prediction: ', category, ' ', score, '\\n')\n",
    "            \n",
    "        else:\n",
    "            print('prediction: ', score,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>How best can we protect ourselves from #COVID1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>@anoush941 Plan to #SocialDistance for 4 weeks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>#COVID19 Plan to #SocialDistance for 4 weeks o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>All the info on the Coronavirus has mentioned ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>Please listen and share. And wash your hands! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              tweet  label\n",
       "0  2020-02-16  How best can we protect ourselves from #COVID1...      2\n",
       "1  2020-02-25  @anoush941 Plan to #SocialDistance for 4 weeks...      0\n",
       "2  2020-02-25  #COVID19 Plan to #SocialDistance for 4 weeks o...      0\n",
       "3  2020-02-27  All the info on the Coronavirus has mentioned ...      0\n",
       "4  2020-03-06  Please listen and share. And wash your hands! ...      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sd = pd.read_csv('labeled v1/socialdistance_labeled.csv',usecols=[1,2,3])\n",
    "df_sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>@anoush941 Plan to #SocialDistance for 4 weeks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>#COVID19 Plan to #SocialDistance for 4 weeks o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>All the info on the Coronavirus has mentioned ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>Please listen and share. And wash your hands! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>@medicalaxioms Please spread hygiene measures ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date                                              tweet  label\n",
       "0      1  2020-02-25  @anoush941 Plan to #SocialDistance for 4 weeks...      0\n",
       "1      2  2020-02-25  #COVID19 Plan to #SocialDistance for 4 weeks o...      0\n",
       "2      3  2020-02-27  All the info on the Coronavirus has mentioned ...      0\n",
       "3      4  2020-03-06  Please listen and share. And wash your hands! ...      0\n",
       "4      5  2020-03-07  @medicalaxioms Please spread hygiene measures ...      0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_uncertain = df_sd[df_sd['label']<=1]\n",
    "sd_uncertain = sd_uncertain.reset_index()\n",
    "sd_uncertain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11799\n",
      "There aren’t real people who think kids can social distance, right? Mono was going around the 10th grade this year, and I still saw them sharing drinks. Not to mention little kids like mine, that just lick each other for now reason. #SocialDistance #ShelterInPlace\n",
      "prediction:  positive   0.3401376008987427 \n",
      "\n",
      "9059\n",
      "How Amazon Has Continued to Exploit Workers During the Pandemic  https://t.co/I4inSAEesh If #coronavirusfear was gone would you still protest or would you accept the risk and quietly ask for changes in system? Bad timing! #doctors&amp;nurses can't #socialdistance from patients.\n",
      "prediction:  neutral/irrelevant   0.21334707736968994 \n",
      "\n",
      "6997\n",
      "@b_base haha sometimes it's funny to see how people post their opinion on critical topics like an expert at Facebook. #SocialDistance yourself from them, stay safe :)\n",
      "prediction:  neutral/irrelevant   -0.1244615912437439 \n",
      "\n",
      "13177\n",
      "07 - Orange and Gold Face Mask  https://t.co/U3W7RMffqj via @zazzle #orange #gold #checkers #abstract #drawing #facemask #protection #accessories #health #safety #socialdistance #washable #pattern #zazzle\n",
      "prediction:  positive   0.8384485840797424 \n",
      "\n",
      "23405\n",
      "Oh the irony! #COVIDIOT   @MarkMeadows admitted the GOP is \"not going control the pandemic.\" #TrumpDeathToll236K  #TrumpKnewAndDidNothing   Follow @CDC guidelines #WearAMask #SocialDistance #WashYourHands #FauciHero #ScienceMatters\n",
      "prediction:  neutral/irrelevant   -0.29509979486465454 \n",
      "\n",
      "18783\n",
      "Justanned triple-layer non-leather anti-pollution and anti-bacterial unisex breathable and reusable face masks. #StaySafeAndStayHealthy #HandWash #SocialDistance #Justanned #FaceMask #Unisex #UnisexFaceMask #JustanneFaceMask #style #MakeInIndia #MasksforSafety #AatmanirbharBharat  https://t.co/wcxU6f2M2M\n",
      "prediction:  positive   0.6682114601135254 \n",
      "\n",
      "9255\n",
      "Watching #DeepImpact on my computer and this scene is how #coronavirus should have been handled by a certain someone #SocialDistance #disasterfilms #Covid_19  https://t.co/wkDJEfGmLU\n",
      "prediction:  neutral/irrelevant   -0.12228220701217651 \n",
      "\n",
      "7266\n",
      "I was just remembering a post I saw with apostrophe abuse and wrong usage of homophones and thought, I have worse things to worry about right now. #perspective #newnormal #socialdistancing #socialdistance #pandemic…  https://t.co/56qy3zkQgi\n",
      "prediction:  neutral/irrelevant   0.05882091075181961 \n",
      "\n",
      "4920\n",
      "Heard the sound of a clown who cried in the alley. #bobdylan  #SocialDistance\n",
      "prediction:  neutral/irrelevant   0.12958398461341858 \n",
      "\n",
      "15414\n",
      "Grabbing a sushi 🍣 to-go with boo and “enjoying” (as much as one can) our fun masks by maskmakingmarine! Thanks Doug!! 🙏🏼😷😷 🍣 🏮🎊 #quarantine #socialDistance #sushi #takeOut #weekend #yums #maskLife #masks #playingItSafe  https://t.co/tg5uS0v4e3\n",
      "prediction:  positive   0.46494224667549133 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweet_and_pred(sd_uncertain, snet, 10, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11331\n",
      "#GreenMask instead #N95  from #India 🇮🇳 #Masks4AllChallenge  #SocialDistance  #COVID19  https://t.co/0MLAh9nVGt\n",
      "prediction:  neutral/irrelevant   0.08014827221632004 \n",
      "\n",
      "26023\n",
      "Hi Americans, please take a good look of the map below. Instant self-gratification will harm you &amp; others. American adults for once, grow up so you'll have holidays to celebrate w/ your children in 2021. #WearAMask #SocialDistance #StayAtHome Stop #Covid_19\n",
      "prediction:  positive   0.8073064684867859 \n",
      "\n",
      "17205\n",
      "Stay SAFE !!  Stay FRESH‼️ #TheBarbersLounge  #Cam  #Bril  #Father  #Son  #SocialDistance  #Covid19  #GenerationalGrooming @ The Barbers Lounge  https://t.co/mRrj0rKu34\n",
      "prediction:  positive   0.5199558138847351 \n",
      "\n",
      "13681\n",
      " https://t.co/kOPnhklDlS #Killer #Viruses🦠 can #Kill⚰️#COVID19 ☣️ has #Killed #Celebrities, #Politicians, Reg #Persons, #Rich &amp; #Poor, #Famous or #Unfamous #People. #Wear #NanoFiber #Masks 😷 #FaceShields 🥽 &amp; #Gloves 🧤 Keep your #SocialDistance 👣 #Protect #Family &amp; #Friends 👨‍👧‍👧\n",
      "prediction:  positive   0.45906803011894226 \n",
      "\n",
      "12171\n",
      "Another great evening with my girls. Grateful for the #bigskystate to #socialdistance in.  https://t.co/OalOXY3rg2\n",
      "prediction:  neutral/irrelevant   0.05407636612653732 \n",
      "\n",
      "14724\n",
      "26 - Colorful Flowers Face Mask  https://t.co/sTZCjUXqKf via @zazzle  #style #fashion #facemask #abstract #drawing #abstractart #protection #accessories #health #safety #socialdistance #washable #pattern #onsale #zazzle\n",
      "prediction:  positive   0.9577128887176514 \n",
      "\n",
      "23197\n",
      "just to put into perspective, the hospital had 62 COVID patients yesterday, and today had 84 :) #WearAMask #SocialDistance\n",
      "prediction:  neutral/irrelevant   -0.06578365713357925 \n",
      "\n",
      "19142\n",
      "We are thinking of all Victorian's during this time, please stay safe #wearamask #socialdistance #weareallinthistogether #stayinghomecanbefun😷😶  https://t.co/0aJ9IZdXCP\n",
      "prediction:  positive   0.564665675163269 \n",
      "\n",
      "15911\n",
      "This is good news for the hospitality industry as it boosts their argument to relax to 2m #SocialDistanacing rule to 1m. It is now more likely we will see the #SocialDistance relaxed to 1m in July for the hospitality sector to reopen.\n",
      "prediction:  positive   0.5668466687202454 \n",
      "\n",
      "5946\n",
      "One of the positive things I have noticed over the past week is the reconnection with family member. Many families are going on walks or bike rides through their neighborhoods while keeping their distance from other people during their explorations. #SocialDistance #COVID19\n",
      "prediction:  neutral/irrelevant   0.19086043536663055 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweet_and_pred(sd_uncertain, snet_v2, 10, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>@HoustonTexuhz @ReemBoi25 Hey @ReemBoi25 make ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>@EricCHenry_ @speedboy_te75 Can’t w8 to see U ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>HELLO FLAMIN EVERYBODY!    #RoadtoPartner  #NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Free Hot Cheeto Bags for Everybody! Anybody wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>SUPER SMASH BROS ULTIMATE! LETS XXTRA FLAMIN G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              tweet  label\n",
       "0  2020-01-06  @HoustonTexuhz @ReemBoi25 Hey @ReemBoi25 make ...      0\n",
       "1  2020-01-08  @EricCHenry_ @speedboy_te75 Can’t w8 to see U ...      0\n",
       "2  2020-01-10  HELLO FLAMIN EVERYBODY!    #RoadtoPartner  #NO...      0\n",
       "3  2020-01-14  Free Hot Cheeto Bags for Everybody! Anybody wa...      0\n",
       "4  2020-01-22  SUPER SMASH BROS ULTIMATE! LETS XXTRA FLAMIN G...      0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other = pd.read_csv('labeled v1/negative_labeled.csv', usecols=[1,2,3])\n",
    "df_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>@HoustonTexuhz @ReemBoi25 Hey @ReemBoi25 make ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>@EricCHenry_ @speedboy_te75 Can’t w8 to see U ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>HELLO FLAMIN EVERYBODY!    #RoadtoPartner  #NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>Free Hot Cheeto Bags for Everybody! Anybody wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>SUPER SMASH BROS ULTIMATE! LETS XXTRA FLAMIN G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date                                              tweet  label\n",
       "0      0  2020-01-06  @HoustonTexuhz @ReemBoi25 Hey @ReemBoi25 make ...      0\n",
       "1      1  2020-01-08  @EricCHenry_ @speedboy_te75 Can’t w8 to see U ...      0\n",
       "2      2  2020-01-10  HELLO FLAMIN EVERYBODY!    #RoadtoPartner  #NO...      0\n",
       "3      3  2020-01-14  Free Hot Cheeto Bags for Everybody! Anybody wa...      0\n",
       "4      4  2020-01-22  SUPER SMASH BROS ULTIMATE! LETS XXTRA FLAMIN G...      0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_uncertain = df_other[df_other['label']<=1].reset_index()\n",
    "other_uncertain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30138\n",
      "@TheSolariReport \"COVID is a mild, self-limiting disease 97% of the time unless you're a kid-- then you can't get it at all.\" - Dr. Tim O'Shea   https://t.co/JP9gveYthk  #COVID19 #SCAMdemic\n",
      "prediction:  negative   -0.9551659822463989 \n",
      "\n",
      "2801\n",
      "#gop #democrats #republicans #nomask #redstates  This is why people who had to actually work that shit show are now infected.  I wonder if all the VIP participants have health insurance thru the government.  Socialism for the privilege.\n",
      "prediction:  negative   -0.5231501460075378 \n",
      "\n",
      "13426\n",
      "one year ago more or less #CertificateOfVaccinationID #Controlavirus #BillAndMelindaGatesFoundation #Plandemic #WHO #IMF #Rockefeller #OrderFollowers #MindControl #Mindfulness #Awake #alternativeHEALING #ScientificDictatorship #Fear #GlobalEconomicCollapse  https://t.co/ziTcx1Vqek\n",
      "prediction:  neutral/irrelevant   -0.01744580641388893 \n",
      "\n",
      "10808\n",
      "Listen Up! #Plandemic @realDonaldTrump  https://t.co/ZeilS8pyJj\n",
      "prediction:  neutral/irrelevant   -0.12470266222953796 \n",
      "\n",
      "17610\n",
      "Hospitals ordered to bypass the CDC and send COVID-19 data directly to Trump administration   https://t.co/aDwu3v2ezg #COVID19 #plandemic #vaccine #CDC #WHO\n",
      "prediction:  negative   -0.7003740072250366 \n",
      "\n",
      "1919\n",
      "@GovSisolak @GovHerbert @GovPritzker MASKS ARE USELESS  #MaskUpAmerica #MaskUpNevada #MaskupNV #Masks #Mask #NoMask #NoMasks #UnmaskNV #UnMaskNevada #NoMaskNevada #NoMaskNV #UnMaskAmerica  https://t.co/DJC8kKKEL2\n",
      "prediction:  negative   -0.9578407406806946 \n",
      "\n",
      "34179\n",
      "Nothing!  That's why we have now this #scamdemic and COVID misery. The same club running the show but for too long now. Enough!\n",
      "prediction:  neutral/irrelevant   -0.1937064826488495 \n",
      "\n",
      "20926\n",
      "@StogieMcGruff @Acosta Global #Plandemic has been played out. Gotta come up with a new scheme.\n",
      "prediction:  negative   -0.7158613204956055 \n",
      "\n",
      "31745\n",
      "“ThE eCoNoMy ShRUnK 32% in Q2”  ...well yeah, you fools shut down the whole country over the biggest hoax of our lifetime? #Scamdemic #ItsJustTheFluWithAScientificName\n",
      "prediction:  negative   -0.8697715401649475 \n",
      "\n",
      "22646\n",
      "I'm in Poland, absolutely no masks, no unsocial distancing, they also think its  bollocks! #plandemic\n",
      "prediction:  negative   -0.7228148579597473 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweet_and_pred(other_uncertain, snet_v2, 10, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
